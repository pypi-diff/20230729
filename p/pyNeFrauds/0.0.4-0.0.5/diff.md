# Comparing `tmp/pyNeFrauds-0.0.4-py3-none-any.whl.zip` & `tmp/pyNeFrauds-0.0.5-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,22 +1,23 @@
-Zip file size: 14378 bytes, number of entries: 20
--rw-rw-r--  2.0 unx     4735 b- defN 23-Apr-06 02:46 PyNeFrauds/Constructor.py
--rw-rw-r--  2.0 unx      110 b- defN 23-Apr-17 08:13 PyNeFrauds/Globals.py
--rw-rw-r--  2.0 unx     3413 b- defN 23-Apr-17 08:34 PyNeFrauds/Neo4jHandler.py
--rw-rw-r--  2.0 unx     1564 b- defN 23-Apr-17 08:15 PyNeFrauds/QueryConstructor.py
--rw-rw-r--  2.0 unx       86 b- defN 23-Apr-18 14:52 PyNeFrauds/__init__.py
--rw-rw-r--  2.0 unx     2873 b- defN 23-Apr-06 02:42 PyNeFrauds/extractor.py
--rw-rw-r--  2.0 unx     5851 b- defN 23-Apr-18 02:29 PyNeFrauds/nn/EmbedFetcher.py
--rw-rw-r--  2.0 unx     2025 b- defN 23-Apr-18 06:03 PyNeFrauds/nn/Evaluation.py
--rw-rw-r--  2.0 unx     1028 b- defN 23-Apr-18 02:44 PyNeFrauds/nn/ModelBuilder.py
--rw-rw-r--  2.0 unx      901 b- defN 23-Apr-18 07:39 PyNeFrauds/nn/Trainer.py
--rw-rw-r--  2.0 unx      179 b- defN 23-Apr-18 05:38 PyNeFrauds/nn/__init__.py
--rw-rw-r--  2.0 unx     2483 b- defN 23-Apr-18 07:52 PyNeFrauds/nn/toPyGData.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-18 08:40 PyNeFrauds/tests/__init__.py
--rw-rw-r--  2.0 unx     2721 b- defN 23-Apr-18 11:03 PyNeFrauds/tests/tests.py
--rw-rw-r--  2.0 unx       27 b- defN 23-Apr-18 14:44 PyNeFrauds/tests/unittest_test.py
--rw-rw-r--  2.0 unx     1050 b- defN 23-Apr-18 14:52 pyNeFrauds-0.0.4.dist-info/LICENSE.txt
--rw-rw-r--  2.0 unx      683 b- defN 23-Apr-18 14:52 pyNeFrauds-0.0.4.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-Apr-18 14:52 pyNeFrauds-0.0.4.dist-info/WHEEL
--rw-rw-r--  2.0 unx       11 b- defN 23-Apr-18 14:52 pyNeFrauds-0.0.4.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     1642 b- defN 23-Apr-18 14:52 pyNeFrauds-0.0.4.dist-info/RECORD
-20 files, 31474 bytes uncompressed, 11694 bytes compressed:  62.8%
+Zip file size: 17055 bytes, number of entries: 21
+-rw-rw-rw-  2.0 fat     4893 b- defN 23-Jul-29 08:51 PyNeFrauds/Constructor.py
+-rw-rw-rw-  2.0 fat      112 b- defN 23-Jun-27 11:37 PyNeFrauds/Globals.py
+-rw-rw-rw-  2.0 fat     3513 b- defN 23-Jul-22 16:20 PyNeFrauds/Neo4jHandler.py
+-rw-rw-rw-  2.0 fat     1611 b- defN 23-Jul-29 08:52 PyNeFrauds/QueryConstructor.py
+-rw-rw-rw-  2.0 fat      120 b- defN 23-Jul-19 14:38 PyNeFrauds/__init__.py
+-rw-rw-rw-  2.0 fat     2958 b- defN 23-Jul-29 08:52 PyNeFrauds/extractor.py
+-rw-rw-rw-  2.0 fat     7626 b- defN 23-Jul-28 08:30 PyNeFrauds/neo4j_populator.py
+-rw-rw-rw-  2.0 fat     5975 b- defN 23-Jun-27 11:37 PyNeFrauds/nn/EmbedFetcher.py
+-rw-rw-rw-  2.0 fat     2077 b- defN 23-Jul-29 08:40 PyNeFrauds/nn/Evaluation.py
+-rw-rw-rw-  2.0 fat     1057 b- defN 23-Jun-27 11:37 PyNeFrauds/nn/ModelBuilder.py
+-rw-rw-rw-  2.0 fat      928 b- defN 23-Jun-27 11:37 PyNeFrauds/nn/Trainer.py
+-rw-rw-rw-  2.0 fat      185 b- defN 23-Jun-27 11:37 PyNeFrauds/nn/__init__.py
+-rw-rw-rw-  2.0 fat     2533 b- defN 23-Jun-27 11:37 PyNeFrauds/nn/toPyGData.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Jun-27 11:37 PyNeFrauds/tests/__init__.py
+-rw-rw-rw-  2.0 fat     2779 b- defN 23-Jul-15 06:32 PyNeFrauds/tests/tests.py
+-rw-rw-rw-  2.0 fat       28 b- defN 23-Jun-27 11:37 PyNeFrauds/tests/unittest_test.py
+-rw-rw-rw-  2.0 fat     1056 b- defN 23-Jul-29 08:59 pyNeFrauds-0.0.5.dist-info/LICENSE.txt
+-rw-rw-rw-  2.0 fat      702 b- defN 23-Jul-29 08:59 pyNeFrauds-0.0.5.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 23-Jul-29 08:59 pyNeFrauds-0.0.5.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       11 b- defN 23-Jul-29 08:59 pyNeFrauds-0.0.5.dist-info/top_level.txt
+-rw-rw-r--  2.0 fat     1729 b- defN 23-Jul-29 08:59 pyNeFrauds-0.0.5.dist-info/RECORD
+21 files, 39985 bytes uncompressed, 14237 bytes compressed:  64.4%
```

## zipnote {}

```diff
@@ -12,14 +12,17 @@
 
 Filename: PyNeFrauds/__init__.py
 Comment: 
 
 Filename: PyNeFrauds/extractor.py
 Comment: 
 
+Filename: PyNeFrauds/neo4j_populator.py
+Comment: 
+
 Filename: PyNeFrauds/nn/EmbedFetcher.py
 Comment: 
 
 Filename: PyNeFrauds/nn/Evaluation.py
 Comment: 
 
 Filename: PyNeFrauds/nn/ModelBuilder.py
@@ -39,23 +42,23 @@
 
 Filename: PyNeFrauds/tests/tests.py
 Comment: 
 
 Filename: PyNeFrauds/tests/unittest_test.py
 Comment: 
 
-Filename: pyNeFrauds-0.0.4.dist-info/LICENSE.txt
+Filename: pyNeFrauds-0.0.5.dist-info/LICENSE.txt
 Comment: 
 
-Filename: pyNeFrauds-0.0.4.dist-info/METADATA
+Filename: pyNeFrauds-0.0.5.dist-info/METADATA
 Comment: 
 
-Filename: pyNeFrauds-0.0.4.dist-info/WHEEL
+Filename: pyNeFrauds-0.0.5.dist-info/WHEEL
 Comment: 
 
-Filename: pyNeFrauds-0.0.4.dist-info/top_level.txt
+Filename: pyNeFrauds-0.0.5.dist-info/top_level.txt
 Comment: 
 
-Filename: pyNeFrauds-0.0.4.dist-info/RECORD
+Filename: pyNeFrauds-0.0.5.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## PyNeFrauds/Constructor.py

```diff
@@ -1,158 +1,158 @@
-from enum import Enum
-
-
-class ConstrType(Enum):
-    NONE = None
-    LIST = 0
-    RANGE = 1
-    REGEX = 2
-
-
-# START functions for constructing conditions
-
-def mergeNodeConditions(queries, nRef, nLabel):
-    '''queries: dict { priority level : list of sub-queries}
-    nRef: node reference to use in query
-    nLabel: node label
-    Merges for each level and 
-    returns a query for each priority level
-    '''
-    merged = {}
-    for level in queries:
-        query = ' OR '.join(queries[level])
-        merged[level] = query
-    return merged
-
-
-def constrType(restraint):
-    '''Identify its type: range, regex, list, etc
-    Accepted types:
-    list -> list
-    dict -> numerical range
-    str -> regex
-    #TODO more detailed checks: range has min,max?
-    '''
-    if isinstance(restraint, list):
-        return ConstrType.LIST
-    if isinstance(restraint, dict):
-        return ConstrType.RANGE
-    if isinstance(restraint, str):
-        return ConstrType.REGEX
-    return ConstrType.NONE
-
-
-def constrQuery(preCondition, restraint, nRef, aRef):
-    '''
-    preCondition: "IS", "IS NOT", "IN", "NOT IN".
-    restraint: constraint
-    nRef: Node reference to use in query
-    aRef: attribute name
-    Identifies what kind of restraint it is.
-    Constructs query for it.
-    Returns: CYPHER query for this restraint.'''
-    typ = constrType(restraint)
-    if 'NOT' in preCondition.split():
-        query = " NOT "
-    else:
-        query = ""
-    query += "("+nRef+"."+aRef
-    if typ == ConstrType.LIST:
-        query += " IN " + str(restraint)
-    elif typ == ConstrType.RANGE:
-        query += f' {list(restraint.keys())[0]} {list(restraint.values())[0]} '
-        if len(restraint) > 1:
-            query += f' AND {nRef}.{aRef} '
-            query += f'{list(restraint.keys())[1]} {list(restraint.values())[1]} '
-    elif typ == ConstrType.REGEX:
-        query += " =~ '" + restraint + "'"
-    else:
-        query = ""
-    query += ')'
-    return query
-
-
-def constrNodeCond(node, nRef='n'):
-    '''node: a node's schema
-    nRef: node reference to use in queries
-    Construct queries for a node.
-    Returns:
-    {
-        level : [list of queries],
-        .
-        .
-    }'''
-    queries = {}
-
-    def addQuery(query, level):
-        if level in queries:
-            queries[level].append(query)
-        else:
-            queries[level] = [query]
-    # Construct queries for attributes
-    for idx in node['Attributes']:
-        attr, preCondition, restraint = idx[:3]
-        # set default value of 1
-        restrLevel = 1 if len(idx) < 4 else idx[-1]
-        query = constrQuery(preCondition, restraint, nRef, attr)
-        addQuery(query, restrLevel)
-
-    # TODO Construct queries for nodeProperties
-
-    query = mergeNodeConditions(
-        queries=queries, nRef=nRef, nLabel=node['NodeLabel'])
-    return query
-
-################################ END condition Constructing functions #########################
-
-
-def constrNodeQueries(nodeTests, nRef):
-    '''<dict> nodeTests: tests on the node attributes
-    <str> nRef: node reference to use in query
-    returns: {level : query} for every level in dict nodeTests'''
-    queries = {}
-    for level in nodeTests:
-        query = f'MATCH ({nRef}) \n WHERE '
-        query += nodeTests[level]
-        query += f' \nRETURN {nRef} \n'
-        queries[level] = query
-    return queries
-
-
-def constructQueries(jsonSchema, mode='STREAM'):
-    '''
-    jsonSchema: node schema for whole graph.
-    mode: #TODO
-        STREAM = displays the nodes who fail conditions on the browser,
-        WRITE = Sets a node property according to the evaluation of condition
-    returns queries for nodes.
-    '''
-    queries = {}
-    for node in jsonSchema:
-        nRef = 'n'
-        nodeTests = constrNodeCond(node, nRef=nRef)
-        nodeQueries = constrNodeQueries(nodeTests, nRef=nRef)
-        queries[node['NodeLabel']] = nodeQueries
-    return queries
-
-
-def all_in_one_query(entityList):
-    if len(entityList) == 0:
-        return ""
-    # json input to queries
-    finalQuery = ''
-    for ent in entityList:
-        # match the entity
-        if ent['type'] == 'node':
-            query = f'\nMATCH ({ent["ref"]}:{ent["NodeLabel"]})'
-        elif ent['type'] == 'relationship':
-            query = f'\nMATCH ({ent["source"]})-[{ent["ref"]}:{ent["NodeLabel"]}]-({ent["dest"]})'
-        # where properties : conditions
-        if len(ent['Attributes']) > 0:
-            entTests = constrNodeCond(ent, nRef=ent['ref'])
-            query += "\n  WHERE " + entTests[1]
-        finalQuery += "\n"+query
-    finalQuery = finalQuery[2:] + f'\n\nRETURN {entityList[0]["ref"]}'
-    for ent in entityList[1:]:
-        finalQuery += f', {ent["ref"]}'
-    # return all refs
-    return finalQuery
+from enum import Enum
+
+
+class ConstrType(Enum):
+    NONE = None
+    LIST = 0
+    RANGE = 1
+    REGEX = 2
+
+
+# START functions for constructing conditions
+
+def mergeNodeConditions(queries, nRef, nLabel):
+    """queries: dict { priority level : list of sub-queries}
+    nRef: node reference to use in query
+    nLabel: node label
+    Merges for each level and 
+    returns a query for each priority level
+    """
+    merged = {}
+    for level in queries:
+        query = ' OR '.join(queries[level])
+        merged[level] = query
+    return merged
+
+
+def constrType(restraint):
+    """Identify its type: range, regex, list, etc
+    Accepted types:
+    list -> list
+    dict -> numerical range
+    str -> regex
+    #TODO more detailed checks: range has min,max?
+    """
+    if isinstance(restraint, list):
+        return ConstrType.LIST
+    if isinstance(restraint, dict):
+        return ConstrType.RANGE
+    if isinstance(restraint, str):
+        return ConstrType.REGEX
+    return ConstrType.NONE
+
+
+def constrQuery(preCondition, restraint, nRef, aRef):
+    """
+    preCondition: "IS", "IS NOT", "IN", "NOT IN".
+    restraint: constraint
+    nRef: Node reference to use in query
+    aRef: attribute name
+    Identifies what kind of restraint it is.
+    Constructs query for it.
+    Returns: CYPHER query for this restraint."""
+    typ = constrType(restraint)
+    if 'NOT' in preCondition.split():
+        query = " NOT "
+    else:
+        query = ""
+    query += "("+nRef+"."+aRef
+    if typ == ConstrType.LIST:
+        query += " IN " + str(restraint)
+    elif typ == ConstrType.RANGE:
+        query += f' {list(restraint.keys())[0]} {list(restraint.values())[0]} '
+        if len(restraint) > 1:
+            query += f' AND {nRef}.{aRef} '
+            query += f'{list(restraint.keys())[1]} {list(restraint.values())[1]} '
+    elif typ == ConstrType.REGEX:
+        query += " =~ '" + restraint + "'"
+    else:
+        query = ""
+    query += ')'
+    return query
+
+
+def constrNodeCond(node, nRef='n'):
+    """node: a node's schema
+    nRef: node reference to use in queries
+    Construct queries for a node.
+    Returns:
+    {
+        level : [list of queries],
+        .
+        .
+    }"""
+    queries = {}
+
+    def addQuery(query, level):
+        if level in queries:
+            queries[level].append(query)
+        else:
+            queries[level] = [query]
+    # Construct queries for attributes
+    for idx in node['Attributes']:
+        attr, preCondition, restraint = idx[:3]
+        # set default value of 1
+        restrLevel = 1 if len(idx) < 4 else idx[-1]
+        query = constrQuery(preCondition, restraint, nRef, attr)
+        addQuery(query, restrLevel)
+
+    # TODO Construct queries for nodeProperties
+
+    query = mergeNodeConditions(
+        queries=queries, nRef=nRef, nLabel=node['NodeLabel'])
+    return query
+
+################################ END condition Constructing functions #########################
+
+
+def constrNodeQueries(nodeTests, nRef):
+    """<dict> nodeTests: tests on the node attributes
+    <str> nRef: node reference to use in query
+    returns: {level : query} for every level in dict nodeTests"""
+    queries = {}
+    for level in nodeTests:
+        query = f'MATCH ({nRef}) \n WHERE '
+        query += nodeTests[level]
+        query += f' \nRETURN {nRef} \n'
+        queries[level] = query
+    return queries
+
+
+def constructQueries(jsonSchema, mode='STREAM'):
+    """
+    jsonSchema: node schema for whole graph.
+    mode: #TODO
+        STREAM = displays the nodes who fail conditions on the browser,
+        WRITE = Sets a node property according to the evaluation of condition
+    returns queries for nodes.
+    """
+    queries = {}
+    for node in jsonSchema:
+        nRef = 'n'
+        nodeTests = constrNodeCond(node, nRef=nRef)
+        nodeQueries = constrNodeQueries(nodeTests, nRef=nRef)
+        queries[node['NodeLabel']] = nodeQueries
+    return queries
+
+
+def all_in_one_query(entityList):
+    if len(entityList) == 0:
+        return ""
+    # json input to queries
+    finalQuery = ''
+    for ent in entityList:
+        # match the entity
+        if ent['type'] == 'node':
+            query = f'\nMATCH ({ent["ref"]}:{ent["NodeLabel"]})'
+        elif ent['type'] == 'relationship':
+            query = f'\nMATCH ({ent["source"]})-[{ent["ref"]}:{ent["NodeLabel"]}]-({ent["dest"]})'
+        # where properties : conditions
+        if len(ent['Attributes']) > 0:
+            entTests = constrNodeCond(ent, nRef=ent['ref'])
+            query += "\n  WHERE " + entTests[1]
+        finalQuery += "\n"+query
+    finalQuery = finalQuery[2:] + f'\n\nRETURN {entityList[0]["ref"]}'
+    for ent in entityList[1:]:
+        finalQuery += f', {ent["ref"]}'
+    # return all refs
+    return finalQuery
```

## PyNeFrauds/Globals.py

 * *Ordering differences only*

```diff
@@ -1,2 +1,2 @@
-from .Neo4jHandler import Neo4jHandler
-neo4jHandler = Neo4jHandler() #handles interaction with Neo4j database
+from .Neo4jHandler import Neo4jHandler
+neo4jHandler = Neo4jHandler() #handles interaction with Neo4j database
```

## PyNeFrauds/Neo4jHandler.py

 * *Ordering differences only*

```diff
@@ -1,100 +1,100 @@
-"""
-Handles the interaction with neo4j.
-- Holds the credentials
-- Executed the given queries
-"""
-from neo4j import GraphDatabase
-
-
-class Neo4jHandler():
-    """Handles the interaction with neo4j.
-        - Holds the credentials
-        - Executed the given queries
-    """
-
-    def __init__(self, host=None, user=None, password=None):
-        """_summary_
-
-        Args:
-            host (str, optional): The host url where neo4j database is hosted. Defaults to None. e.g, 'bolt://localhost:11003'
-            user (str, optional): The username in the database. Defaults to None.
-            password (str, optional): Defaults to None.
-        """
-        self.host = host
-        self.user = user
-        self.password = password
-        return
-
-    def query(self, query, params=None, password=None, user=None, host=None):
-        """Executes the given query in the neo4j database.
-
-        Args:
-            query (str): _description_
-            params (str, optional): Parameters for the query. Defaults to None.
-            password (str, optional): Defaults to stored password.
-            user (str, optional): Defaults to stored user.
-            host (str, optional): Defaults to stored host.
-
-        Returns:
-            list: list of records of the result.
-        """
-        host = self.host if host is None else host
-        user = self.user if user is None else user
-        password = self.password if password is None else password
-        driver = GraphDatabase.driver(host, auth=(user, password))
-        with driver.session() as session:
-            result = session.run(query, params)
-            return [record.data() for record in result]
-
-    def set_credentials(self, host, user, password=None):
-        self.host = host
-        self.user = user
-        self.password = password
-        return
-
-    def get_credentials(self):
-        return self.host, self.user, self.password
-
-    def validate_credentials(self, password=None):
-        password = self.password if password is None else password
-        try:
-            driver = GraphDatabase.driver(
-                self.host, auth=(self.user, password))
-            return True
-        except Exception as e:
-            return False
-
-    def get_schema(self, password=None):
-        """Assumes the neo4j database has APOC plugin installed.
-
-        Args:
-            password (str, optional): Defaults to stored password.
-
-        Returns:
-            Schema: Result of 'CALL apoc.meta.schema()'
-        """
-        password = self.password if password is None else password
-        query = 'CALL apoc.meta.schema()'
-        result = self.query(query=query, password=password)
-        return result[0]['value']
-
-    def get_processed_schema(self, password=None):
-        schema = self.get_schema(password=password)
-        filteredSchema = {}
-        for idx in schema:
-            entity = schema[idx]
-            fEntity = {}
-            fEntity['type'] = entity['type']
-            fEntity['properties'] = entity['properties']
-            filteredSchema[idx] = fEntity
-        return filteredSchema
-
-if __name__ == '__main__':
-    host = 'bolt://localhost:11003'
-    user = "neo4j"
-    password = "password"
-    querer = Neo4jHandler(host, user)
-    # query = "MATCH (n) RETURN n LIMIT 5"
-    # result = querer.query(query=query, password=password)
-    result = querer.get_processed_schema(password="password")
-    print(result)
+"""
+Handles the interaction with neo4j.
+- Holds the credentials
+- Executed the given queries
+"""
+from neo4j import GraphDatabase
+
+
+class Neo4jHandler():
+    """Handles the interaction with neo4j.
+        - Holds the credentials
+        - Executed the given queries
+    """
+
+    def __init__(self, host=None, user=None, password=None):
+        """_summary_
+
+        Args:
+            host (str, optional): The host url where neo4j database is hosted. Defaults to None. e.g, 'bolt://localhost:11003'
+            user (str, optional): The username in the database. Defaults to None.
+            password (str, optional): Defaults to None.
+        """
+        self.host = host
+        self.user = user
+        self.password = password
+        return
+
+    def query(self, query, params=None, password=None, user=None, host=None):
+        """Executes the given query in the neo4j database.
+
+        Args:
+            query (str): _description_
+            params (str, optional): Parameters for the query. Defaults to None.
+            password (str, optional): Defaults to stored password.
+            user (str, optional): Defaults to stored user.
+            host (str, optional): Defaults to stored host.
+
+        Returns:
+            list: list of records of the result.
+        """
+        host = self.host if host is None else host
+        user = self.user if user is None else user
+        password = self.password if password is None else password
+        driver = GraphDatabase.driver(host, auth=(user, password))
+        with driver.session() as session:
+            result = session.run(query, params)
+            return [record.data() for record in result]
+
+    def set_credentials(self, host, user, password=None):
+        self.host = host
+        self.user = user
+        self.password = password
+        return
+
+    def get_credentials(self):
+        return self.host, self.user, self.password
+
+    def validate_credentials(self, password=None):
+        password = self.password if password is None else password
+        try:
+            driver = GraphDatabase.driver(
+                self.host, auth=(self.user, password))
+            return True
+        except Exception as e:
+            return False
+
+    def get_schema(self, password=None):
+        """Assumes the neo4j database has APOC plugin installed.
+
+        Args:
+            password (str, optional): Defaults to stored password.
+
+        Returns:
+            Schema: Result of 'CALL apoc.meta.schema()'
+        """
+        password = self.password if password is None else password
+        query = 'CALL apoc.meta.schema()'
+        result = self.query(query=query, password=password)
+        return result[0]['value']
+
+    def get_processed_schema(self, password=None):
+        schema = self.get_schema(password=password)
+        filteredSchema = {}
+        for idx in schema:
+            entity = schema[idx]
+            fEntity = {}
+            fEntity['type'] = entity['type']
+            fEntity['properties'] = entity['properties']
+            filteredSchema[idx] = fEntity
+        return filteredSchema
+
+if __name__ == '__main__':
+    host = 'bolt://localhost:11003'
+    user = "neo4j"
+    password = "password"
+    querer = Neo4jHandler(host, user)
+    # query = "MATCH (n) RETURN n LIMIT 5"
+    # result = querer.query(query=query, password=password)
+    result = querer.get_processed_schema(password="password")
+    print(result)
```

## PyNeFrauds/QueryConstructor.py

```diff
@@ -1,47 +1,47 @@
-from .Globals import *
-from .extractor import extractSchema
-from .Constructor import constructQueries, all_in_one_query
-
-import json
-    
-class QueryConstructor():
-    '''This class is a master controller/coordinator.
-    It uses extractor.py to verify and extract the schema from jsonString.'''
-    def __init__(self, jsonString):
-        '''
-        jsonString: A string following json format, the schema will be extracted from this.
-
-        '''
-        self.schema = extractSchema(jsonString, verify=False)
-        self.extractMetadata()
-        self.constructQueries()
-    
-    def extractMetadata(self):
-        '''From self.schema extracts following and sets as self. properties:
-        # of nodes schema,
-        list of types of nodes,'''
-        self.numTypes = len(self.schema) #number of node types
-        self.nodeTypes = [node['NodeLabel'] for node in self.schema]
-
-    def constructQueries(self, mode="INDIVIDUAL"):
-        '''From self.schema
-        constructs CYPHER queries for fraud detection.'''
-        if mode=="INDIVIDUAL":
-            self.queries = constructQueries(self.schema)
-        elif mode=="MERGED":
-            self.queries = all_in_one_query(self.schema)
-        return
-
-    def showQueries(self):
-        if isinstance(self.queries, dict):
-            for node, nodeQueries in self.queries.items():
-                print(f'\nNode: {node}')
-                for level, query in nodeQueries.items():
-                    print(f'Level: {level}')
-                    print(query)
-        else:
-            print(self.queries)
-
-
-
-
+from .Globals import *
+from .extractor import extractSchema
+from .Constructor import constructQueries, all_in_one_query
+
+import json
+    
+class QueryConstructor():
+    """This class is a master controller/coordinator.
+    It uses extractor.py to verify and extract the schema from jsonString."""
+    def __init__(self, jsonString):
+        """
+        jsonString: A string following json format, the schema will be extracted from this.
+
+        """
+        self.schema = extractSchema(jsonString, verify=False)
+        self.extractMetadata()
+        self.constructQueries()
+    
+    def extractMetadata(self):
+        """From self.schema extracts following and sets as self. properties:
+        # of nodes schema,
+        list of types of nodes,"""
+        self.numTypes = len(self.schema) #number of node types
+        self.nodeTypes = [node['NodeLabel'] for node in self.schema]
+
+    def constructQueries(self, mode="INDIVIDUAL"):
+        """From self.schema
+        constructs CYPHER queries for fraud detection."""
+        if mode=="INDIVIDUAL":
+            self.queries = constructQueries(self.schema)
+        elif mode=="MERGED":
+            self.queries = all_in_one_query(self.schema)
+        return
+
+    def showQueries(self):
+        if isinstance(self.queries, dict):
+            for node, nodeQueries in self.queries.items():
+                print(f'\nNode: {node}')
+                for level, query in nodeQueries.items():
+                    print(f'Level: {level}')
+                    print(query)
+        else:
+            print(self.queries)
+
+
+
+
```

## PyNeFrauds/__init__.py

```diff
@@ -1,3 +1,4 @@
-from .Globals import *
-from .QueryConstructor import QueryConstructor
-from . import nn
+from .Globals import *
+from .QueryConstructor import QueryConstructor
+from . import nn
+from .neo4j_populator import *
```

## PyNeFrauds/extractor.py

```diff
@@ -1,83 +1,84 @@
-import json
-
-def verifyLabel(label):
-    '''The label should be string. This is the nodeLabel/nodeType
-    returns label with modifications if required.'''
-    if not isinstance(label, str):
-        raise TypeError("label should be of type str")
-    return label
-
-def verifyAttributeProperties(properties):
-    '''properties of attribute should be of type list.
-    returns properties with modifications if required.'''
-    if not isinstance(properties, list):
-        raise TypeError("properties of attribute should be of type list.")
-    #TODO
-    return properties
-
-def verifyAttributes(attributes):
-    '''attributes should be of type dict. These are the node attributes.
-        {
-            "nameOfAttribute" : list(properties of attribute)
-        }
-        returns: attributes with modifications if needed.
-    '''
-    if not isinstance(attributes, list):
-        raise TypeError("attributes should be of type list")
-    result = []
-    for attribute in attributes:
-        result.append(verifyAttributeProperties(attribute))
-    return result
-
-def verifyNodeProperties(nodeProps):
-    '''NodeProperties should be of type dict.
-    These are the meta properties of the node like degree, neighbours, etc'''
-    if not isinstance(nodeProps, dict):
-        raise TypeError('NodeProperties should be of type dict')
-    #TODO: check if valid
-    return nodeProps
-
-
-def verifyNode(node):
-    '''node: a dict type.
-    node dict should have:
-        nodeLabel:<str>;
-        <dict>: Attributes;
-        <dict>: NodeProperties;
-        <dict>: AttributeRelations;
-    in the same order.
-    returns: verified node, with minor modifications if needed.'''
-    if not isinstance(node, dict):
-        raise TypeError("node should be of type python dict.")
-    NodeLabel = verifyLabel(node['NodeLabel'])
-    Attributes= verifyAttributes(node['Attributes'])
-    NodeProperties = verifyNodeProperties(node['NodeProperties'])
-
-    return {"NodeLabel":NodeLabel, 'Attributes':Attributes, "NodeProperties":NodeProperties}
-
-
-def verifySchema(nodesList):
-    '''
-    nodesList: A list of json dict, where each dict represents a node schema.
-    returns: verified nodeList, with minor modifications in it if needed.
-    '''
-    if not isinstance(nodesList, list):
-        raise TypeError("nodesList should be of type python list.")
-
-    rectifiedList = []
-    for node in nodesList:
-        rectifiedList.append( verifyNode(node))
-    return rectifiedList
-
-
-
-def extractSchema(jsonString, verify=True):
-    '''Given a jsonString, extracts schema for PyNe.
-    jsonString should confirm to standard json format.
-    Returns: A list of nodes schemas as dicts.
-    '''
-    #TODO: Check if jsonString is tooo large or smth. Vulnerability: might stall/crash program.
-    parsedJson = json.loads(jsonString)
-    if verify:
-        parsedJson = verifySchema(parsedJson)
-    return parsedJson
+import json
+
+def verifyLabel(label):
+    """The label should be string. This is the nodeLabel/nodeType
+    returns label with modifications if required."""
+    if not isinstance(label, str):
+        raise TypeError("label should be of type str")
+    return label
+
+
+def verifyAttributeProperties(properties):
+    """properties of attribute should be of type list.
+    returns properties with modifications if required."""
+    if not isinstance(properties, list):
+        raise TypeError("properties of attribute should be of type list.")
+    #TODO
+    return properties
+
+def verifyAttributes(attributes):
+    """attributes should be of type dict. These are the node attributes.
+        {
+            "nameOfAttribute" : list(properties of attribute)
+        }
+        returns: attributes with modifications if needed.
+    """
+    if not isinstance(attributes, list):
+        raise TypeError("attributes should be of type list")
+    result = []
+    for attribute in attributes:
+        result.append(verifyAttributeProperties(attribute))
+    return result
+
+def verifyNodeProperties(nodeProps):
+    """NodeProperties should be of type dict.
+    These are the meta properties of the node like degree, neighbours, etc"""
+    if not isinstance(nodeProps, dict):
+        raise TypeError('NodeProperties should be of type dict')
+    #TODO: check if valid
+    return nodeProps
+
+
+def verifyNode(node):
+    """node: a dict type.
+    node dict should have:
+        nodeLabel:<str>;
+        <dict>: Attributes;
+        <dict>: NodeProperties;
+        <dict>: AttributeRelations;
+    in the same order.
+    returns: verified node, with minor modifications if needed."""
+    if not isinstance(node, dict):
+        raise TypeError("node should be of type python dict.")
+    NodeLabel = verifyLabel(node['NodeLabel'])
+    Attributes= verifyAttributes(node['Attributes'])
+    NodeProperties = verifyNodeProperties(node['NodeProperties'])
+
+    return {"NodeLabel":NodeLabel, 'Attributes':Attributes, "NodeProperties":NodeProperties}
+
+
+def verifySchema(nodesList):
+    """
+    nodesList: A list of json dict, where each dict represents a node schema.
+    returns: verified nodeList, with minor modifications in it if needed.
+    """
+    if not isinstance(nodesList, list):
+        raise TypeError("nodesList should be of type python list.")
+
+    rectifiedList = []
+    for node in nodesList:
+        rectifiedList.append( verifyNode(node))
+    return rectifiedList
+
+
+
+def extractSchema(jsonString, verify=True):
+    """Given a jsonString, extracts schema for PyNe.
+    jsonString should confirm to standard json format.
+    Returns: A list of nodes schemas as dicts.
+    """
+    #TODO: Check if jsonString is tooo large or smth. Vulnerability: might stall/crash program.
+    parsedJson = json.loads(jsonString)
+    if verify:
+        parsedJson = verifySchema(parsedJson)
+    return parsedJson
```

## PyNeFrauds/nn/EmbedFetcher.py

 * *Ordering differences only*

```diff
@@ -1,124 +1,124 @@
-from ..Globals import *
-import numpy as np
-# import torch
-
-class EmbedFetcher():
-    def __init__(self, embedProperty, uniqueID=None, target=None):
-        """
-        Warning: If uniqueID value is provided and the property doesn't exist in neo4j, then some junk value will be returned.
-        Args:
-            embedProperty (str): the property that contains embeddings
-            uniqueID (str): property that is unique for every node. Defaults to None, in which case neo4j assigned <id> are used.
-            target (str, optional): target value/ground truth property name. Defaults to None.
-        """
-        self.embedProperty = embedProperty
-        self.uniqueID = uniqueID
-        self.target = target
-    
-    def fetch_node_embeddings(self, nodeType=None):
-        """Gets the node embedding of specified NodeType from the specified node embedding property from neo4j.
-        If uniqueID is set to None, then uses neo4j assigned unique id as primary key to identify nodes and
-            sets self.uniqueID as 'Neo4jID'.
-
-        Args:
-            nodeType (str, optional): Specific node type of which embeddings are required. 
-                Defaults to None and extracts for all node type(Assuming all node types have self.embedProperty as their property).
-        Returns:
-            list: Result of CYPHER query executed on neo4j.
-        """
-        query = f'MATCH (n{"" if nodeType is None else ":"+nodeType}) \
-            RETURN {"id(n)" if self.uniqueID is None else "n."+self.uniqueID} as {"Neo4jID" if self.uniqueID is None else self.uniqueID}, \
-              labels(n) as Label, n.{self.embedProperty} as {self.embedProperty}, n.{self.target} as {self.target}'
-        result = neo4jHandler.query(query)
-        self.embeddings = result
-        return result
-
-    def set_ref_indexes(self):
-        """Assigns a unique integer to all the nodes. 
-        This integers form the index of this nodes in the feature matrix and same is used to indicate nodes in COO edge matrix too.
-
-        Returns:
-            dict: {"unique_id":"index"}
-        """
-        self.REF_INDEX = {}
-        for i, node in enumerate(self.embeddings):
-            self.REF_INDEX[node[ "Neo4jID" if self.uniqueID is None else self.uniqueID]] = i
-        return self.REF_INDEX
-
-
-
-    def fetch_feature_matrix(self):
-        """Fetches the self.embedProperty values for all nodes from neo4j.  
-            Sets the fetched feature matrix as self.featureMatrix in tensor form.
-
-        Returns:
-            numpy.ndarray: feature matrix 
-        """
-        featureMatrix = np.zeros((len(self.embeddings), len(self.embeddings[0][self.embedProperty])))
-        uniqueID = "Neo4jID" if self.uniqueID is None else self.uniqueID
-        for node in self.embeddings:
-            featureMatrix[ self.REF_INDEX[node[uniqueID]]] = np.array(node[self.embedProperty])
-        self.featureMatrix = featureMatrix #torch.tensor(featureMatrix, dtype=torch.float)
-        return featureMatrix
-
-
-    def fetch_edge_COO(self,relationName=None, sourceProperty='project_id', destProperty='project_id'):
-        """Fetches the 'relationName' relations from neo4j database. Converts into COO edge_index.
-        Sets self.edge_index as fetched edge_COO in tensor form. 
-
-        Args:
-            relationName (_type_, optional): _description_. Defaults to None.
-            sourceProperty (str, optional): _description_. Defaults to 'project_id'.
-            destProperty (str, optional): _description_. Defaults to 'project_id'.
-
-        Returns:
-            _type_: _description_
-        """
-        query = f'MATCH (n)-[r{"" if relationName is None else ":"+relationName}]->(m) \
-            RETURN  COLLECT({ "[id(n),id(m)]" if self.uniqueID is None else "[n." +self.uniqueID+" , m."+self.uniqueID+"]"}) as edge'
-        result = neo4jHandler.query(query)
-        unprocessed = result[0]['edge']
-        processed = [[self.REF_INDEX[x[0]],self.REF_INDEX[x[1]]] for x in unprocessed]
-        self.edge_index = processed #torch.tensor(processed, dtype=torch.long)
-        return processed
-
-
-    def set_targets(self):
-        """From self.embeddings sets the self.targets. sets to None if self.target is None.
-            self.targets are the values of the property with name {self.targets} in neo4j database.
-        Returns:
-            self.targets
-        """
-        if self.target is None:
-            self.targets=None
-            return None
-        self.targets = np.zeros(len(self.embeddings))
-        for node in self.embeddings:
-            self.targets[ self.REF_INDEX[node["Neo4jID" if self.uniqueID is None else self.uniqueID]]] = np.array(node[self.target])
-        return self.targets
-
-
-    def fetchData(self,nodeType=None, relName=None,):
-        """Fetches the embeddings from neo4j. Transforms into feature matrix, edge index, targets form and sends back.
-
-        Args:
-            nodeType (str, optional): Specific nodeType only which needs to be present in feature matrix. 
-                    Defaults to None, fetches for all nodes(Assuming all nodeTypes possess {self.embedProperty}).
-            relName (str, optional): Specific relation only which needs to be formed edge index.
-                     Defaults to None, fetches all relations in COO format.
-
-        Returns:
-            self.REF_INDEX, self.featureMatrix, self.edge_index, targets
-        """
-        #get embeddings and target
-        self.fetch_node_embeddings(nodeType=nodeType)
-        #get new references
-        self.set_ref_indexes()
-        #get feature matrix
-        self.fetch_feature_matrix()
-        #get coo edge-index
-        self.fetch_edge_COO(relationName=relName, sourceProperty=self.uniqueID, destProperty=self.uniqueID)
-        #get targets
-        self.set_targets()
-
-        return self.REF_INDEX, self.featureMatrix, self.edge_index, self.targets
+from ..Globals import *
+import numpy as np
+# import torch
+
+class EmbedFetcher():
+    def __init__(self, embedProperty, uniqueID=None, target=None):
+        """
+        Warning: If uniqueID value is provided and the property doesn't exist in neo4j, then some junk value will be returned.
+        Args:
+            embedProperty (str): the property that contains embeddings
+            uniqueID (str): property that is unique for every node. Defaults to None, in which case neo4j assigned <id> are used.
+            target (str, optional): target value/ground truth property name. Defaults to None.
+        """
+        self.embedProperty = embedProperty
+        self.uniqueID = uniqueID
+        self.target = target
+    
+    def fetch_node_embeddings(self, nodeType=None):
+        """Gets the node embedding of specified NodeType from the specified node embedding property from neo4j.
+        If uniqueID is set to None, then uses neo4j assigned unique id as primary key to identify nodes and
+            sets self.uniqueID as 'Neo4jID'.
+
+        Args:
+            nodeType (str, optional): Specific node type of which embeddings are required. 
+                Defaults to None and extracts for all node type(Assuming all node types have self.embedProperty as their property).
+        Returns:
+            list: Result of CYPHER query executed on neo4j.
+        """
+        query = f'MATCH (n{"" if nodeType is None else ":"+nodeType}) \
+            RETURN {"id(n)" if self.uniqueID is None else "n."+self.uniqueID} as {"Neo4jID" if self.uniqueID is None else self.uniqueID}, \
+              labels(n) as Label, n.{self.embedProperty} as {self.embedProperty}, n.{self.target} as {self.target}'
+        result = neo4jHandler.query(query)
+        self.embeddings = result
+        return result
+
+    def set_ref_indexes(self):
+        """Assigns a unique integer to all the nodes. 
+        This integers form the index of this nodes in the feature matrix and same is used to indicate nodes in COO edge matrix too.
+
+        Returns:
+            dict: {"unique_id":"index"}
+        """
+        self.REF_INDEX = {}
+        for i, node in enumerate(self.embeddings):
+            self.REF_INDEX[node[ "Neo4jID" if self.uniqueID is None else self.uniqueID]] = i
+        return self.REF_INDEX
+
+
+
+    def fetch_feature_matrix(self):
+        """Fetches the self.embedProperty values for all nodes from neo4j.  
+            Sets the fetched feature matrix as self.featureMatrix in tensor form.
+
+        Returns:
+            numpy.ndarray: feature matrix 
+        """
+        featureMatrix = np.zeros((len(self.embeddings), len(self.embeddings[0][self.embedProperty])))
+        uniqueID = "Neo4jID" if self.uniqueID is None else self.uniqueID
+        for node in self.embeddings:
+            featureMatrix[ self.REF_INDEX[node[uniqueID]]] = np.array(node[self.embedProperty])
+        self.featureMatrix = featureMatrix #torch.tensor(featureMatrix, dtype=torch.float)
+        return featureMatrix
+
+
+    def fetch_edge_COO(self,relationName=None, sourceProperty='project_id', destProperty='project_id'):
+        """Fetches the 'relationName' relations from neo4j database. Converts into COO edge_index.
+        Sets self.edge_index as fetched edge_COO in tensor form. 
+
+        Args:
+            relationName (_type_, optional): _description_. Defaults to None.
+            sourceProperty (str, optional): _description_. Defaults to 'project_id'.
+            destProperty (str, optional): _description_. Defaults to 'project_id'.
+
+        Returns:
+            _type_: _description_
+        """
+        query = f'MATCH (n)-[r{"" if relationName is None else ":"+relationName}]->(m) \
+            RETURN  COLLECT({ "[id(n),id(m)]" if self.uniqueID is None else "[n." +self.uniqueID+" , m."+self.uniqueID+"]"}) as edge'
+        result = neo4jHandler.query(query)
+        unprocessed = result[0]['edge']
+        processed = [[self.REF_INDEX[x[0]],self.REF_INDEX[x[1]]] for x in unprocessed]
+        self.edge_index = processed #torch.tensor(processed, dtype=torch.long)
+        return processed
+
+
+    def set_targets(self):
+        """From self.embeddings sets the self.targets. sets to None if self.target is None.
+            self.targets are the values of the property with name {self.targets} in neo4j database.
+        Returns:
+            self.targets
+        """
+        if self.target is None:
+            self.targets=None
+            return None
+        self.targets = np.zeros(len(self.embeddings))
+        for node in self.embeddings:
+            self.targets[ self.REF_INDEX[node["Neo4jID" if self.uniqueID is None else self.uniqueID]]] = np.array(node[self.target])
+        return self.targets
+
+
+    def fetchData(self,nodeType=None, relName=None,):
+        """Fetches the embeddings from neo4j. Transforms into feature matrix, edge index, targets form and sends back.
+
+        Args:
+            nodeType (str, optional): Specific nodeType only which needs to be present in feature matrix. 
+                    Defaults to None, fetches for all nodes(Assuming all nodeTypes possess {self.embedProperty}).
+            relName (str, optional): Specific relation only which needs to be formed edge index.
+                     Defaults to None, fetches all relations in COO format.
+
+        Returns:
+            self.REF_INDEX, self.featureMatrix, self.edge_index, targets
+        """
+        #get embeddings and target
+        self.fetch_node_embeddings(nodeType=nodeType)
+        #get new references
+        self.set_ref_indexes()
+        #get feature matrix
+        self.fetch_feature_matrix()
+        #get coo edge-index
+        self.fetch_edge_COO(relationName=relName, sourceProperty=self.uniqueID, destProperty=self.uniqueID)
+        #get targets
+        self.set_targets()
+
+        return self.REF_INDEX, self.featureMatrix, self.edge_index, self.targets
```

## PyNeFrauds/nn/Evaluation.py

```diff
@@ -1,50 +1,51 @@
-import matplotlib
-import matplotlib.pyplot as plt
-from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report
-import os
-
-
-
-def ConfusionMatrix(data, model, use_test_mask=False, saveFig=None, display=False):
-    """Generates confusion matrix and classification report using sklearn. Displays classification report in terminal.
-
-    Args:
-        data (torch_geometric.data.Data): Should have targets.
-        model (nn.Module): torch model
-        use_test_mask (bool, optional): If True then takes only non-masked nodes for classification. Defaults to False.
-        saveFig (str, optional): If "" saves into "Pictures" folder else to specified folder. Defaults to None - means no saving.
-        display (bool, optional): If tkinter is installed then displays the confusion matrix. Generates error if tkinter not installed. Defaults to False.
-    """
-    if display:
-        matplotlib.use("TkAgg")
-    if use_test_mask:
-        # only on masked nodes
-        test_mask = ~data.train_mask
-
-    y_pred = model(data.x, data.edge_index.T)
-    y_pred = y_pred.argmax(dim=1)
-
-    y_pred_test = (y_pred[test_mask]
-                   if use_test_mask else y_pred).detach().numpy()
-    y_test = (data.y[test_mask] if use_test_mask else data.y).detach().numpy()
-
-    cm = confusion_matrix(y_true=y_test, y_pred=y_pred_test)
-
-    dcm = ConfusionMatrixDisplay(
-        confusion_matrix=cm, display_labels=['Non Fraud', 'Fraud'])
-
-    dcm.plot(cmap='Purples')
-    plt.title('Confusion Matrix')
-    if display:
-        plt.show()
-
-    if saveFig is not None:
-        picture_folder = saveFig
-        name = "confusion_matrix.png"
-        if saveFig=="":
-            # Specify the path to the "Pictures" folder in home directory
-            picture_folder = os.path.join(os.path.expanduser("~"), "Pictures")
-        plt.savefig(os.path.join(picture_folder, name))
-        print(f'Confusion matrix saved as "{name}" at {picture_folder}')
-
-    print(classification_report(y_pred=y_pred_test, y_true=y_test))
+import matplotlib
+import matplotlib.pyplot as plt
+from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report
+import os
+
+
+
+def ConfusionMatrix(data, model, use_test_mask=False, saveFig=None, display=False):
+    """Generates confusion matrix and classification report using sklearn. Displays classification report in terminal.
+
+    Args:
+        data (torch_geometric.data.Data): Should have targets.
+        model (nn.Module): torch model
+        use_test_mask (bool, optional): If True then takes only non-masked nodes for classification. Defaults to False.
+        saveFig (str, optional): If "" saves into "Pictures" folder else to specified folder. Defaults to None - means no saving.
+        display (bool, optional): If tkinter is installed then displays the confusion matrix. Generates error if tkinter not installed. Defaults to False.
+    """
+    if display:
+        matplotlib.use("TkAgg")
+    if use_test_mask:
+        # only on masked nodes
+        test_mask = ~data.train_mask
+
+    y_pred = model(data.x, data.edge_index.T)
+    y_pred = y_pred.argmax(dim=1)
+
+    y_pred_test = (y_pred[test_mask]
+                   if use_test_mask else y_pred).detach().numpy()
+    y_test = (data.y[test_mask] if use_test_mask else data.y).detach().numpy()
+
+    print(classification_report(y_pred=y_pred_test, y_true=y_test))
+
+    cm = confusion_matrix(y_true=y_test, y_pred=y_pred_test)
+
+    dcm = ConfusionMatrixDisplay(
+        confusion_matrix=cm, display_labels=['Non Fraud', 'Fraud'])
+
+    dcm.plot(cmap='Purples')
+    plt.title('Confusion Matrix')
+    if display:
+        plt.show()
+
+    if saveFig is not None:
+        picture_folder = saveFig
+        name = "confusion_matrix.png"
+        if saveFig=="":
+            # Specify the path to the "Pictures" folder in home directory
+            picture_folder = os.path.join(os.path.expanduser("~"), "Pictures")
+        plt.savefig(os.path.join(picture_folder, name))
+        print(f'Confusion matrix saved as "{name}" at {picture_folder}')
+
```

## PyNeFrauds/nn/ModelBuilder.py

 * *Ordering differences only*

```diff
@@ -1,30 +1,30 @@
-import torch.nn as tnn
-import torch_geometric.nn as tgnn
-
-from collections import OrderedDict
-
-class NNModel(tnn.Module):
-    """A base neural network class which can handle layers of both torch and torch_geometric.
-    The user needs to give modules as orderedDict. The class will handle creation of the network and forward method too.
-    Extends: torch.nn.Module
-    """
-    def __init__(self, modules):
-        """Sets the modules as self.layers.
-
-        Args:
-            modules (OrderedDict): Ordered dict of modules, can be of both torch and torch_geometric.
-        """
-        super(NNModel, self).__init__()
-        self.layers = tnn.Sequential(modules)
-    
-    def forward(self, x, edge_index):
-        h = x
-
-        for layer in self.layers:
-            h = (h, edge_index)
-            if isinstance(layer, tgnn.conv.MessagePassing): #layers that needs (x,edge_index) as inputs
-                h = layer(*h)
-            else:  #layers that need only (x) as input
-                h = layer(h[0])
-
+import torch.nn as tnn
+import torch_geometric.nn as tgnn
+
+from collections import OrderedDict
+
+class NNModel(tnn.Module):
+    """A base neural network class which can handle layers of both torch and torch_geometric.
+    The user needs to give modules as orderedDict. The class will handle creation of the network and forward method too.
+    Extends: torch.nn.Module
+    """
+    def __init__(self, modules):
+        """Sets the modules as self.layers.
+
+        Args:
+            modules (OrderedDict): Ordered dict of modules, can be of both torch and torch_geometric.
+        """
+        super(NNModel, self).__init__()
+        self.layers = tnn.Sequential(modules)
+    
+    def forward(self, x, edge_index):
+        h = x
+
+        for layer in self.layers:
+            h = (h, edge_index)
+            if isinstance(layer, tgnn.conv.MessagePassing): #layers that needs (x,edge_index) as inputs
+                h = layer(*h)
+            else:  #layers that need only (x) as input
+                h = layer(h[0])
+
         return h
```

## PyNeFrauds/nn/Trainer.py

 * *Ordering differences only*

```diff
@@ -1,27 +1,27 @@
-import torch
-from .ModelBuilder import NNModel
-
-def train(model, data, criterion=None, optimizer=None, n_epoch=20, quiet=False, print_interval=1):
-
-    criterion = torch.nn.CrossEntropyLoss() if criterion is None else criterion
-    optimizer = torch.optim.Adam(model.parameters(), lr=0.01) if optimizer is None else optimizer
-
-    losses = []
-    accuracies = []
-
-    for epoch in range(n_epoch):
-        optimizer.zero_grad()
-        y_pred = model(data.x, data.edge_index.T)
-        loss = criterion(y_pred, data.y)
-        # acc = accuracy(y_pred.argmax(dim=1), data.y)
-        loss.backward()
-        optimizer.step()
-
-        losses.append(loss.item())
-        # accuracies.append(acc)
-
-        if not quiet and epoch % (print_interval) == 0:
-            print(
-                f'epoch: {epoch}/{n_epoch} \t loss:{loss:.3f}') # \t f1-score:{acc*100:.3f}')
-
-    return model, losses #, accuracies
+import torch
+from .ModelBuilder import NNModel
+
+def train(model, data, criterion=None, optimizer=None, n_epoch=20, quiet=False, print_interval=1):
+
+    criterion = torch.nn.CrossEntropyLoss() if criterion is None else criterion
+    optimizer = torch.optim.Adam(model.parameters(), lr=0.01) if optimizer is None else optimizer
+
+    losses = []
+    accuracies = []
+
+    for epoch in range(n_epoch):
+        optimizer.zero_grad()
+        y_pred = model(data.x, data.edge_index.T)
+        loss = criterion(y_pred, data.y)
+        # acc = accuracy(y_pred.argmax(dim=1), data.y)
+        loss.backward()
+        optimizer.step()
+
+        losses.append(loss.item())
+        # accuracies.append(acc)
+
+        if not quiet and epoch % (print_interval) == 0:
+            print(
+                f'epoch: {epoch}/{n_epoch} \t loss:{loss:.3f}') # \t f1-score:{acc*100:.3f}')
+
+    return model, losses #, accuracies
```

## PyNeFrauds/nn/__init__.py

 * *Ordering differences only*

```diff
@@ -1,6 +1,6 @@
-from .EmbedFetcher import EmbedFetcher
-from .toPyGData import PyGDataWrapper
-from .ModelBuilder import NNModel
-from .Trainer import train
-from .Evaluation import ConfusionMatrix
-
+from .EmbedFetcher import EmbedFetcher
+from .toPyGData import PyGDataWrapper
+from .ModelBuilder import NNModel
+from .Trainer import train
+from .Evaluation import ConfusionMatrix
+
```

## PyNeFrauds/nn/toPyGData.py

 * *Ordering differences only*

```diff
@@ -1,51 +1,51 @@
-import torch
-from torch_geometric.data import Data
-import numpy as np
-import random
-
-class PyGDataWrapper():
-    def __init__(self, featureMatrix=None, edge_index=None, targets=None ):
-        """Class that wraps the torch_geometric.data.Data for this library.
-        Aim is to make handling, manipulating torch_geometric accepted data easy.
-        Stores torch_geometric.data.Data in self.data
-        Args: [Can be of type numpy.ndarray or python number list, transforms and stores them as torch.tensor()]
-            featureMatrix (optional): Defaults to None.
-            edge_index (optional): Defaults to None.
-            targets (optional): Defaults to None.
-        """
-        featureMatrix = None if featureMatrix is None else torch.tensor(featureMatrix, dtype=torch.float)
-        edge_index = None if edge_index is None else torch.tensor(edge_index, dtype=torch.long)
-        # ty = torch.tensor([[1,0] if x==0 else [0,1] for x in targets], dtype=torch.float) #One hot encoding.
-        y = None if targets is None else torch.tensor(targets, dtype=torch.long)
-
-        if all(x is not None for x in [featureMatrix, edge_index]):
-            self.data = Data(x=featureMatrix, edge_index=edge_index, y=y)
-        else:
-            self.data = None
-    
-    def from_embed_fetcher(self, embedFetched, frac=0):
-        """Automatically get torch_geometric accepted data format from the EmbedFetcher object.
-
-        Args:
-            embedFetched (EmbedFetcher): object
-        """
-        x = torch.tensor(embedFetched.featureMatrix, dtype=torch.float)
-        edge_index = torch.tensor(embedFetched.edge_index, dtype=torch.long)
-        y = None if embedFetched.targets is None else torch.tensor(embedFetched.targets, dtype=torch.long)
-        self.data = Data(x=x, edge_index=edge_index, y=y)
-        self.set_train_mask(frac=frac)
-
-    def set_train_mask(self, frac):
-        n_nodes = self.data.x.shape[0]
-        n_mask = int(frac * n_nodes) #no of nodes to be not used for training
-        train_mask = torch.tensor(np.array([True]*n_nodes))
-
-        mask_indexes = random.sample(list(range(0,n_nodes)), n_mask)
-        train_mask[mask_indexes] = False
-        self.data.train_mask = train_mask
-
-    def show_data_info(self):
-        # Print information about the dataset
-        print(f'\nNumber of nodes: {self.data.x.shape[0]}')
-        print(f'Number of features: {self.data.num_features}')
+import torch
+from torch_geometric.data import Data
+import numpy as np
+import random
+
+class PyGDataWrapper():
+    def __init__(self, featureMatrix=None, edge_index=None, targets=None ):
+        """Class that wraps the torch_geometric.data.Data for this library.
+        Aim is to make handling, manipulating torch_geometric accepted data easy.
+        Stores torch_geometric.data.Data in self.data
+        Args: [Can be of type numpy.ndarray or python number list, transforms and stores them as torch.tensor()]
+            featureMatrix (optional): Defaults to None.
+            edge_index (optional): Defaults to None.
+            targets (optional): Defaults to None.
+        """
+        featureMatrix = None if featureMatrix is None else torch.tensor(featureMatrix, dtype=torch.float)
+        edge_index = None if edge_index is None else torch.tensor(edge_index, dtype=torch.long)
+        # ty = torch.tensor([[1,0] if x==0 else [0,1] for x in targets], dtype=torch.float) #One hot encoding.
+        y = None if targets is None else torch.tensor(targets, dtype=torch.long)
+
+        if all(x is not None for x in [featureMatrix, edge_index]):
+            self.data = Data(x=featureMatrix, edge_index=edge_index, y=y)
+        else:
+            self.data = None
+    
+    def from_embed_fetcher(self, embedFetched, frac=0):
+        """Automatically get torch_geometric accepted data format from the EmbedFetcher object.
+
+        Args:
+            embedFetched (EmbedFetcher): object
+        """
+        x = torch.tensor(embedFetched.featureMatrix, dtype=torch.float)
+        edge_index = torch.tensor(embedFetched.edge_index, dtype=torch.long)
+        y = None if embedFetched.targets is None else torch.tensor(embedFetched.targets, dtype=torch.long)
+        self.data = Data(x=x, edge_index=edge_index, y=y)
+        self.set_train_mask(frac=frac)
+
+    def set_train_mask(self, frac):
+        n_nodes = self.data.x.shape[0]
+        n_mask = int(frac * n_nodes) #no of nodes to be not used for training
+        train_mask = torch.tensor(np.array([True]*n_nodes))
+
+        mask_indexes = random.sample(list(range(0,n_nodes)), n_mask)
+        train_mask[mask_indexes] = False
+        self.data.train_mask = train_mask
+
+    def show_data_info(self):
+        # Print information about the dataset
+        print(f'\nNumber of nodes: {self.data.x.shape[0]}')
+        print(f'Number of features: {self.data.num_features}')
         print(f'Has isolated nodes: {self.data.has_isolated_nodes()}')
```

## PyNeFrauds/tests/tests.py

```diff
@@ -1,101 +1,101 @@
-# from PyNeFrauds.Globals import neo4jHandler
-import PyNeFrauds.QueryConstructor as QueryConstructor
-from PyNeFrauds.nn import EmbedFetcher
-from PyNeFrauds.nn import PyGDataWrapper
-from PyNeFrauds.nn import NNModel
-from PyNeFrauds.nn import train, ConfusionMatrix
-
-import torch.nn as tnn
-import torch_geometric.nn as tgnn
-
-from collections import OrderedDict
-# from PyNeFrauds.Constructor import testFun
-# from PyNeFrauds.extractor import verifyAttributeProperties
-
-
-# Query Constructor
-json_text = '''
-[{
-  "NodeLabel" : "Patient",
-  "ref" : "n0",
-  "type" : "node",
-  "Attributes" : [
-    ["Name", "IS NOT OF", "w"],
-    ["Contact", "IS", {">" : 9999999999}],
-    ["Age", "IS NOT", {"<=":130}],
-    ["asdf", "IS", {"<":23, ">=":"n1.Cost"}],
-    ["ID", "IS NOT", {"<":0}],
-    ["Gender", "NOT IN", ["Male","Female","Others"]]
-  ],
-  "NodeProperties" : {}
-},
-{
-  "NodeLabel" : "Treatment",
-  "ref" : "n1",
-  "type" : "node",
-  "Attributes" : [
-    ["Name", "IS OF", "w"],
-    ["Cost", "IS", {"=":5000}],
-    ["asdf", "IS", {"<":23, ">=":14}],
-    ["ID", "IS", {"<":0}],
-    ["Category", "IN", ["Oncology","Pediatrics"]]
-  ],
-  "NodeProperties" : {}
-}]
-'''
-
-# Generating queries
-# print(PyNeFrauds.Globals.neo4jHandler.get_credentials())
-
-# cone = QueryConstructor(json_text)
-# print(cone.queries)
-# print(cone.queries['Patient'][1])
-# cone.constructQueries(mode='MERGED')
-# cone.showQueries()
-
-# neo4j credentials
-src.Globals.neo4jHandler.set_credentials("bolt://localhost:11003", "neo4j","password")
-
-# fetching embeddings from neo4j
-x = src.nn.EmbedFetcher(embedProperty="fastRP", uniqueID=None, target="fraud")
-REF_INDEX, featureMatrix, edge_index, targets = x.fetchData()
-# print(x.fetch_node_embeddings()[0])
-
-# creating torch_geometric data
-dWrap = PyGDataWrapper()
-dWrap.from_embed_fetcher(x, frac=0.2)
-dWrap.show_data_info()
-# print(edge_index)
-
-# Building GNN model
-modules = OrderedDict({
-    'GCN1' : tgnn.GCNConv(7, 30),
-    'drop0': tnn.Dropout(p=0.5),
-    'relu1': tnn.ReLU(),
-    'GCN2' : tgnn.GCNConv(30, 40),
-    'relu1': tnn.ReLU(),
-    'linear': tnn.Linear(40,512),
-    'relul1': tnn.ReLU(),
-    'drop1': tnn.Dropout(p=0.2),
-    'linear2': tnn.Linear(512,2),
-    'softmax': tnn.Softmax(dim=1)
-})
-
-#building usual NN model
-input_dim=7
-hidden_dim=128
-output_dim=2
-modules2 = OrderedDict({
-      'Linear1': tnn.Linear(input_dim, hidden_dim),
-      'relu1':tnn.ReLU(),
-      'Linear2':tnn.Linear(hidden_dim, output_dim),
-      'softmax':tnn.Softmax(dim=1)
-})
-model = NNModel(modules=modules)
-print(model)
-
-# Training model
-train(model=model, data=dWrap.data, n_epoch=601, print_interval=30)
-
-# Evaluating using confusion matrix
-ConfusionMatrix(model=model, data=dWrap.data, use_test_mask=True, saveFig="")
+2
+import PyNeFrauds.QueryConstructor as QueryConstructor
+from PyNeFrauds.nn import EmbedFetcher
+from PyNeFrauds.nn import PyGDataWrapper
+from PyNeFrauds.nn import NNModel
+from PyNeFrauds.nn import train, ConfusionMatrix
+
+import torch.nn as tnn
+import torch_geometric.nn as tgnn
+
+from collections import OrderedDict
+# from PyNeFrauds.Constructor import testFun4
+# from PyNeFrauds.extractor import verifyAttributeProperties
+
+
+# Query Constructor
+json_text = '''
+[{
+  "NodeLabel" : "Patient",
+  "ref" : "n0",
+  "type" : "node",
+  "Attributes" : [
+    ["Name", "IS NOT OF", "w"],
+    ["Contact", "IS", {">" : 9999999999}],
+    ["Age", "IS NOT", {"<=":130}],
+    ["asdf", "IS", {"<":23, ">=":"n1.Cost"}],
+    ["ID", "IS NOT", {"<":0}],
+    ["Gender", "NOT IN", ["Male","Female","Others"]]
+  ],
+  "NodeProperties" : {}
+},
+{
+  "NodeLabel" : "Treatment",
+  "ref" : "n1",
+  "type" : "node",
+  "Attributes" : [
+    ["Name", "IS OF", "w"],
+    ["Cost", "IS", {"=":5000}],
+    ["asdf", "IS", {"<":23, ">=":14}],
+    ["ID", "IS", {"<":0}],
+    ["Category", "IN", ["Oncology","Pediatrics"]]
+  ],
+  "NodeProperties" : {}
+}]
+'''
+
+# Generating queries
+# print(PyNeFrauds.Globals.neo4jHandler.get_credentials())
+
+# cone = QueryConstructor(json_text)
+# print(cone.queries)
+# print(cone.queries['Patient'][1])
+# cone.constructQueries(mode='MERGED')
+# cone.showQueries()
+
+# neo4j credentials
+src.Globals.neo4jHandler.set_credentials("bolt://localhost:11003", "neo4j","password")
+
+# fetching embeddings from neo4j
+x = src.nn.EmbedFetcher(embedProperty="fastRP", uniqueID=None, target="fraud")
+REF_INDEX, featureMatrix, edge_index, targets = x.fetchData()
+# print(x.fetch_node_embeddings()[0])
+
+# creating torch_geometric data
+dWrap = PyGDataWrapper()
+dWrap.from_embed_fetcher(x, frac=0.2)
+dWrap.show_data_info()
+# print(edge_index)
+
+# Building GNN model
+modules = OrderedDict({
+    'GCN1' : tgnn.GCNConv(7, 30),
+    'drop0': tnn.Dropout(p=0.5),
+    'relu1': tnn.ReLU(),
+    'GCN2' : tgnn.GCNConv(30, 40),
+    'relu1': tnn.ReLU(),
+    'linear': tnn.Linear(40,512),
+    'relul1': tnn.ReLU(),
+    'drop1': tnn.Dropout(p=0.2),
+    'linear2': tnn.Linear(512,2),
+    'softmax': tnn.Softmax(dim=1)
+})
+
+#building usual NN model
+input_dim=7
+hidden_dim=128
+output_dim=2
+modules2 = OrderedDict({
+      'Linear1': tnn.Linear(input_dim, hidden_dim),
+      'relu1':tnn.ReLU(),
+      'Linear2':tnn.Linear(hidden_dim, output_dim),
+      'softmax':tnn.Softmax(dim=1)
+})
+model = NNModel(modules=modules)
+print(model)
+
+# Training model
+train(model=model, data=dWrap.data, n_epoch=601, print_interval=30)
+
+# Evaluating using confusion matrix
+ConfusionMatrix(model=model, data=dWrap.data, use_test_mask=True, saveFig="")
```

## PyNeFrauds/tests/unittest_test.py

 * *Ordering differences only*

```diff
@@ -1,2 +1,2 @@
-# import unittest
+# import unittest
 import ..
```

## Comparing `pyNeFrauds-0.0.4.dist-info/LICENSE.txt` & `pyNeFrauds-0.0.5.dist-info/LICENSE.txt`

 * *Ordering differences only*

 * *Files 2% similar despite different names*

```diff
@@ -1,7 +1,7 @@
-Copyright 2023, Deepam Rai
-
-Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
-
+Copyright 2023, Deepam Rai
+
+Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
+
 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
```

## Comparing `pyNeFrauds-0.0.4.dist-info/METADATA` & `pyNeFrauds-0.0.5.dist-info/METADATA`

 * *Files 9% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-Metadata-Version: 2.1
-Name: pyNeFrauds
-Version: 0.0.4
-Summary: Python library that integrates with neo4j facilitating in fraud detection using deep learning techniques.
-Author: Deepam Rai
-License: MIT
-Classifier: Programming Language :: Python :: 3
-Classifier: License :: OSI Approved :: MIT License
-Classifier: Operating System :: OS Independent
-Description-Content-Type: text/markdown
-License-File: LICENSE.txt
-Requires-Dist: matplotlib
-Requires-Dist: neo4j
-Requires-Dist: numpy
-Requires-Dist: scikit-learn
-Requires-Dist: torch
-Requires-Dist: torch-geometric
-
-Python Library that integrates with neo4j and aims to make the process of fraud detection using knowledge graphs easier.
+Metadata-Version: 2.1
+Name: pyNeFrauds
+Version: 0.0.5
+Summary: Python library that integrates with neo4j facilitating in fraud detection using deep learning techniques.
+Author: Deepam Rai
+License: MIT
+Classifier: Programming Language :: Python :: 3
+Classifier: License :: OSI Approved :: MIT License
+Classifier: Operating System :: OS Independent
+Description-Content-Type: text/markdown
+License-File: LICENSE.txt
+Requires-Dist: matplotlib
+Requires-Dist: neo4j
+Requires-Dist: numpy
+Requires-Dist: scikit-learn
+Requires-Dist: torch
+Requires-Dist: torch-geometric
+
+Python Library that integrates with neo4j and aims to make the process of fraud detection using knowledge graphs easier.
```

## Comparing `pyNeFrauds-0.0.4.dist-info/RECORD` & `pyNeFrauds-0.0.5.dist-info/RECORD`

 * *Files 20% similar despite different names*

```diff
@@ -1,20 +1,21 @@
-PyNeFrauds/Constructor.py,sha256=urwe8E-33GWrZsbSWYkWSSQMarvUqc6rujsu4OpRmUE,4735
-PyNeFrauds/Globals.py,sha256=lQtryF9kLW3eal8p4dBCUjeHdO-8p1QriF5OixuagtM,110
-PyNeFrauds/Neo4jHandler.py,sha256=joZ7Mziv8PLk0ny-nAJKIf_i9jFlRjgc_OWYF4SmKC0,3413
-PyNeFrauds/QueryConstructor.py,sha256=COTVqXFWpyqABrHkvjJqmr011C4FllnretFDTFOqyKc,1564
-PyNeFrauds/__init__.py,sha256=TdJSko4QwIuQqg00S55DMHyP4ZGGnS8Dny4N-oRITLE,86
-PyNeFrauds/extractor.py,sha256=9I3y0UUDRdCBZNc5fcuwZS_KpIWxd67Ss7IK4ZpDTbc,2873
-PyNeFrauds/nn/EmbedFetcher.py,sha256=YjkzWurkKgUp5xLP0vnZV7_Ic_rxdkNTkVz24TRy2D8,5851
-PyNeFrauds/nn/Evaluation.py,sha256=D4rUMqX3UMnOF6zFvGQUBbdVWWsC6c1jm4vxQmt_QSI,2025
-PyNeFrauds/nn/ModelBuilder.py,sha256=VVFgHiCpDhaJDXE4Vsr5hN1vkXHUaTgEISuaR1Y5X68,1028
-PyNeFrauds/nn/Trainer.py,sha256=PrKadsCZdAmhl_G4ryyfn4ILJtbvCl778OdiGJ-WWFs,901
-PyNeFrauds/nn/__init__.py,sha256=iuwjpxY0GYX9oMVMKq2vW0H4k6UiOXavlno427GboxY,179
-PyNeFrauds/nn/toPyGData.py,sha256=cEw-ChifMNA_vF8lrNVfwZwIN89m7qWzGSw6dOxGYZE,2483
+PyNeFrauds/Constructor.py,sha256=LNBKlcv1W0UDL5Itq5FmO-oN0QPwk8nk9swuKzJLKSk,4893
+PyNeFrauds/Globals.py,sha256=Wfvr29OC4EbIPSya_JQmrIOpVNc60AHwpsX_ivbEW-U,112
+PyNeFrauds/Neo4jHandler.py,sha256=CtLgMXSBdyvMANkliz81Rpsq8eaCYwGJxhADZEJ1ki8,3513
+PyNeFrauds/QueryConstructor.py,sha256=hIkDUfFM-xYySWfTtfSUFaKQmAXiXabU-4BeXhaypwQ,1611
+PyNeFrauds/__init__.py,sha256=FhCp2E8qjsE1_1KF4mPH48ybgeo0_MTPqL9cv3RmV-4,120
+PyNeFrauds/extractor.py,sha256=DC3xId5tFktZir_KqfXX4MZSF88n8-dF3zHNYgC1yzw,2958
+PyNeFrauds/neo4j_populator.py,sha256=OY6ybQO-cw_zLU4O5ySJ8txM_kSbNkczyZCVDPnf3cg,7626
+PyNeFrauds/nn/EmbedFetcher.py,sha256=x92dSAgpkmq5rFkxfeECeIMgUf36h0NUVe9pLBB8bN8,5975
+PyNeFrauds/nn/Evaluation.py,sha256=1Cj8x4JHmswCxiv--yd9NfknlUr7BicNCo8-RWOnJNA,2077
+PyNeFrauds/nn/ModelBuilder.py,sha256=GMG41Rcc9_VoS1GWX2VU3rrhjra7CCV8eumGCZQW4Qw,1057
+PyNeFrauds/nn/Trainer.py,sha256=Seu43hnNXxFfkRHXa4lVJxjIet0VrlIyuJoyYY7js-k,928
+PyNeFrauds/nn/__init__.py,sha256=vyzujoF-U9wMETvyypFFTdgadrQ6sX5TrQWYsDxnOPo,185
+PyNeFrauds/nn/toPyGData.py,sha256=-7BaFuBn6knXcbA4EfM7l4gpGgtnxpx_3eFQK5EVjJk,2533
 PyNeFrauds/tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-PyNeFrauds/tests/tests.py,sha256=s2Rjlhyj73ZoCckukm_wUT1rmJUDP9rsLsLj6gUD6qA,2721
-PyNeFrauds/tests/unittest_test.py,sha256=yuvnAe-uwo0lQUAFKiwE7xYhxt3S2paLuarSaFFy5nY,27
-pyNeFrauds-0.0.4.dist-info/LICENSE.txt,sha256=Y7_zh22DSGssQEoV7hzfqrET9eS_O_Pjwbgbp4TyO0U,1050
-pyNeFrauds-0.0.4.dist-info/METADATA,sha256=Qy7ppNnvCjyFlGafjBpWZCwh7YecryLN3JVzuq3QS7g,683
-pyNeFrauds-0.0.4.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-pyNeFrauds-0.0.4.dist-info/top_level.txt,sha256=_z5ugKVthNv9iObuRHmamNyefsJqoRiCmgj4-Hu3Mlw,11
-pyNeFrauds-0.0.4.dist-info/RECORD,,
+PyNeFrauds/tests/tests.py,sha256=nf3p-Hxgkk4-J_NjEEPDfUmx8hyXjhJoEWjkgNaxurE,2779
+PyNeFrauds/tests/unittest_test.py,sha256=EE9zkfbI4POAWeyojPUT0yE6sy3gYJbzEzeGCy0QnsY,28
+pyNeFrauds-0.0.5.dist-info/LICENSE.txt,sha256=j1kzPTzK70Ss3k4byweXrU2JrdTAIy14CuLuqfXr0a0,1056
+pyNeFrauds-0.0.5.dist-info/METADATA,sha256=aOQuE_afOsv7bNEQjU8BofXpkJCV2n8cfgEKWQ-Rq_k,702
+pyNeFrauds-0.0.5.dist-info/WHEEL,sha256=AtBG6SXL3KF_v0NxLf0ehyVOh0cold-JbJYXNGorC6Q,92
+pyNeFrauds-0.0.5.dist-info/top_level.txt,sha256=_z5ugKVthNv9iObuRHmamNyefsJqoRiCmgj4-Hu3Mlw,11
+pyNeFrauds-0.0.5.dist-info/RECORD,,
```

